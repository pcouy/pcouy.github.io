<!DOCTYPE html>
<html>
    <head>
        <meta charset="utf-8">
        <title>Using a Raspberry Pi to add a second HDMI port to a laptop</title>
        <link rel="stylesheet" href="/main.css">
        <link rel="stylesheet" href="/assets/css/native.css">
    </head>
    <body>
        <div class="site-container">
            <nav>
    
        <a href="/" >
            Home
        </a>
    
    
        
        
        <a href="/category/side-projects/" >
            Side Projects
        </a>
    
</nav>

            <h1>Using a Raspberry Pi to add a second HDMI port to a laptop</h1>
            <div class="post-details">
    11 Mar 2023 
    
        in
            Side Projects
    
    .
    
        Tags :
            
                <a href="/tag/raspberry-pi/">raspberry-pi</a>
                ,
            
                <a href="/tag/ffmpeg/">ffmpeg</a>
                ,
            
                <a href="/tag/tutorial/">tutorial</a>
                ,
            
                <a href="/tag/linux/">linux</a>
                
            
    
</div>

<p>Recently, I purchased a new laptop. I was really focused on spending the least amount of money and had not noticed that the laptop I chose was missing an essential feature : it did not have Display Port over USB C. Not being able to use my second external monitor on this new laptop felt like a huge downgrade from my previous one (which was able to output to both its HDMI and VGA ports simultaneously).</p>

<h2 id="existing-solutions-and-limitations-of-old-raspberry-pi-models">Existing solutions and limitations of old Raspberry Pi models</h2>

<p>I quickly hooked a Raspberry Pi to the external monitor and tried to find a turnkey solution that would allow me to stream a virtual screen to the Pi via an ethernet cable. I looked into using VNC, Steam Remote Play, and some dedicated VNC wrappers I found on GitHub.</p>

<p>Since I was not willing to spend more money on my setup, I used a Raspberry Pi 3 which was sitting unused in one of my drawers. This meant I could not benefit from hardware accelerated h264 decoding, which happened to be a significant limitation for using modern low-latency video streaming solutions. I had to compromise between picture quality, latency and framerate, and could never reach a balance I felt satisfied with : the slow LAN adapter and CPU could not handle my requirements.</p>

<p>I also did not like the fact that most of these solutions depended on running a full desktop session on the Pi, which I wanted to avoid in order to save its thin resources.</p>

<h2 id="goals">Goals</h2>

<p>Since I intended to use this daily, and I could not see myself using anything I had tried, I decided to go for my own solution. I had a clear goal in mind : after setting it up, it should feel as much as using a regular external monitor as possible ; while still being able to run on outdated hardware.</p>

<p>My main requirements were the following :</p>

<ul>
  <li>The latency should not be noticeable when scrolling or moving the mouse</li>
  <li>The picture quality should be high enough to read small text</li>
  <li>Since I planned to mainly use it for static text content, I decided to go easy on myself by setting a low target of 10 FPS.</li>
  <li>Use <a href="https://en.wikipedia.org/wiki/Direct_Rendering_Manager">Direct Rendering Manager</a> to display the stream on the Pi instead of depending on a X server.</li>
  <li>I looked into remote-play tools and VNC because they seemed like easy to use low-latency solutions. However, I was not interested with streaming inputs back from the Pi to the laptop.</li>
</ul>

<p>As I was using a Raspberry Pi 3, I had to consider its limitations :</p>

<ul>
  <li>Due to slow CPU, use a low-overhead protocol and fast to decode encoding</li>
  <li>Due to slow network, use a low-bitrate encoding</li>
  <li>No hardware accelerated h264 decoding</li>
</ul>

<p>Since I was already going to roll my own solution, I also listed some non essential features I would enjoy having, including :</p>

<ul>
  <li>Having a DHCP server on the Raspberry Pi so that I would not have to bother myself with IP settings</li>
  <li>Automatically running the necessary software on the Pi at boot so I never have to hook a keyboard or SSH into it for regular use</li>
  <li>Having the laptop automatically start streaming to the Pi when I enable a given virtual monitor with <code class="language-plaintext highlighter-rouge">xrandr</code> (or one of its GUI wrapper such as <code class="language-plaintext highlighter-rouge">arandr</code>)</li>
  <li>Automatically turning the pi-controlled monitor on and off as if it were a regular monitor hooked to a regular HDMI port</li>
</ul>

<h2 id="making-it-happen">Making it happen</h2>

<p>I knew the hardest part was going to fine-tune the video pipeline between the laptop and the Pi. I wanted to tackle this first and only spend time on other features when I was sure it was worth it.</p>

<p>I chose to encode and send the stream using <a href="https://ffmpeg.org/"><code class="language-plaintext highlighter-rouge">ffmpeg</code></a> on my laptop (which is known to be the swiss-army knife of audio and video manipulation). It takes care of screen-grabbing, video encoding, encapsulation and networking and provides fine-grained controls over all steps. Its numerous options can often feel overwhelming, but digging the docs have never let me down.</p>

<p>For the receiving end, I considered several ffmpeg-compatible video players with Direct Rendering Manager support, including <code class="language-plaintext highlighter-rouge">mpv</code>, <code class="language-plaintext highlighter-rouge">vlc</code>, and <code class="language-plaintext highlighter-rouge">ffplay</code> (more on that topic later).</p>

<h3 id="raspberry-pi-initial-setup">Raspberry Pi initial setup</h3>

<p>I started whith a fresh Raspberry Pi OS install, which I flashed on my SD card using the usual commands :</p>

<figure class="highlight"><pre><code class="language-console" data-lang="console"><span class="gp">pierre@laptop:~ $</span><span class="w"> </span>lsblk <span class="nt">-f</span> <span class="c"># Identify SD card block device</span>
<span class="gp">pierre@laptop:~ $</span><span class="w"> </span><span class="nb">sudo dd </span><span class="k">if</span><span class="o">=</span>2022-09-22-raspios-bullseye-arm64-lite.img <span class="nv">of</span><span class="o">=</span>/dev/sd[SD card letter]</code></pre></figure>

<p>I booted the Pi a first time with the screen and a keyboard attached. This lets Raspberry Pi OS resize the partition to fit the SD card. After connecting the Pi to my home WiFi and enabling SSH using <a href="https://www.raspberrypi.com/documentation/computers/configuration.html"><code class="language-plaintext highlighter-rouge">raspi-config</code></a>, I unplugged the keyboard from the Pi and SSH’ed into it.</p>

<p>I installed the required software to quickly start experimenting with the stream settings :</p>

<figure class="highlight"><pre><code class="language-console" data-lang="console"><span class="gp">pi@raspberrypi:~ $</span><span class="w"> </span><span class="nb">sudo </span>apt-get update <span class="o">&amp;&amp;</span> <span class="nb">sudo </span>apt-get <span class="nb">install </span>mpv ffmpeg</code></pre></figure>

<figure class="highlight"><pre><code class="language-console" data-lang="console"><span class="gp">pierre@laptop:~ $</span><span class="w"> </span><span class="nb">sudo </span>apt-get update <span class="o">&amp;&amp;</span> <span class="nb">sudo </span>apt-get <span class="nb">install </span>ffmpeg</code></pre></figure>

<p>While waiting for the players to install, I found an ethernet cable to use between the Pi and the laptop. To my surprise, both computers seemed to be able to talk to each other without me doing anything, so I started tinkering with ffmpeg parameters. I don’t remember the details, but the connection ended up not being stable enough. It was necessary to install and configure a DHCP server on the Raspberry Pi in order to comfortably experiment.</p>

<figure class="highlight"><pre><code class="language-console" data-lang="console"><span class="gp">pi@raspberrypi:~ $</span><span class="w"> </span><span class="nb">sudo </span>apt-get <span class="nb">install </span>udhcpd
<span class="gp">pi@raspberrypi:~ $</span><span class="w"> </span>sudoedit /etc/udhcpd.conf</code></pre></figure>

<p>This will install <a href="https://manpages.ubuntu.com/manpages/bionic/man5/udhcpd.conf.5.html"><code class="language-plaintext highlighter-rouge">udhcpd</code></a> and open its configuration file with root privileges using the editor set in your <code class="language-plaintext highlighter-rouge">EDITOR</code> shell variable (<code class="language-plaintext highlighter-rouge">nano</code> by default on Raspberry Pi OS). I used the following configuration file :</p>

<figure class="highlight"><pre><code class="language-conf" data-lang="conf"><span class="c"># Only one lease for the Pi itself, and one for the laptop
</span><span class="n">start</span> <span class="m">10</span>.<span class="m">0</span>.<span class="m">0</span>.<span class="m">0</span>
<span class="n">end</span> <span class="m">10</span>.<span class="m">0</span>.<span class="m">0</span>.<span class="m">1</span>

<span class="c"># udhcpd will use eth0
</span><span class="n">interface</span> <span class="n">eth0</span>

<span class="c"># Various options
</span><span class="n">option</span> <span class="n">subnet</span> <span class="m">255</span>.<span class="m">255</span>.<span class="m">255</span>.<span class="m">0</span>
<span class="n">option</span> <span class="n">domain</span> <span class="n">hdmi</span>
<span class="n">option</span> <span class="n">lease</span>  <span class="m">60</span>  <span class="c"># One minute lease
</span>
<span class="c"># The Pi itself will always be 10.0.0.0
</span><span class="n">static_lease</span> [<span class="n">PI</span> <span class="n">MAC</span> <span class="n">ADDRESS</span>] <span class="m">10</span>.<span class="m">0</span>.<span class="m">0</span>.<span class="m">0</span></code></pre></figure>

<p>You will need to replace <code class="language-plaintext highlighter-rouge">[PI MAC ADDRESS]</code> with the actual MAC address of your hardware, which you can find by running <code class="language-plaintext highlighter-rouge">ip a</code> on the Pi (<code class="language-plaintext highlighter-rouge">link/ether</code> field).</p>

<figure class="highlight"><pre><code class="language-console" data-lang="console"><span class="gp">pi@rapsberrypi:~ $</span><span class="w"> </span><span class="nb">sudo </span>systemctl <span class="nb">enable </span>udhcpd
<span class="gp">pi@rapsberrypi:~ $</span><span class="w"> </span><span class="nb">sudo </span>systemctl start udhcpd</code></pre></figure>

<p>The first command above will launch the DHCP server on boot, and the second one will launch it immediately. Rebooting the Pi may help both computers pick up on their new network configurations. From now on, the Raspberry Pi will be reachable from the laptop using <code class="language-plaintext highlighter-rouge">10.0.0.0</code> as long as the ethernet cable is plugged to both. The laptop will use the IP <code class="language-plaintext highlighter-rouge">10.0.0.1</code>.</p>

<h3 id="starting-an-unoptimized-stream">Starting an unoptimized stream</h3>

<p>With this initial setup done, I was able to quickly iterate over commands for sending and receiving the stream. This was not a straightforward process and while I did not keep records of every attempt, I’ll do my best to tell the interesting discoveries I made along the way. I will also detail every option in the commands presented below.</p>

<p>On the Raspberry Pi, the goal was to lauch a media player that would listen on the network waiting for the laptop to send it a stream, and display it using DRM with the lowest possible latency. I first tried using <a href="https://mpv.io/"><code class="language-plaintext highlighter-rouge">mpv</code></a> because of its support for GPU decoding.</p>

<p>Since both ends of the stream were connected over a single wire with no realistic opportunity for interception and I wanted to save resources on the Pi, encryption was not necessary. My requirements for lowest possible latency led my to try streaming over plain UDP. Long story short, my experiments with UDP did not go so well : one skipped packet and the whole screen would turn to garbage (or worse, the player would crash). I then switched to TCP, which proved to offer low-enough latency while not suffering from the same issue.</p>

<p>Let’s start with the most basic command that does that, without bothering with optimization for now :</p>

<figure class="highlight"><pre><code class="language-console" data-lang="console"><span class="gp">pi@raspberrypi:~ $</span><span class="w"> </span>mpv <span class="nt">--hwdec</span><span class="o">=</span>drm <span class="s2">"tcp://10.0.0.0:1234?listen"</span></code></pre></figure>

<p>This command makes mpv listen on interface <code class="language-plaintext highlighter-rouge">10.0.0.0</code>, TCP port <code class="language-plaintext highlighter-rouge">1234</code> and will display the received stream using DRM.</p>

<p>On the sending side, I started with a simple command to test the stream :</p>

<figure class="highlight"><pre><code class="language-console" data-lang="console"><span class="gp">pierre@laptop:~ $</span><span class="w"> </span>ffmpeg <span class="nt">-video_size</span> 1920x1080 <span class="nt">-framerate</span> 5 <span class="nt">-f</span> x11grab <span class="nt">-i</span> :0.0+0x0 <span class="nt">-f</span> mpegts tcp://10.0.0.0:1234</code></pre></figure>

<p>From <code class="language-plaintext highlighter-rouge">man ffmpeg</code>, the syntax is :</p>

<figure class="highlight"><pre><code class="language-console" data-lang="console"><span class="go">ffmpeg [global_options] {[input_file_options] -i input_url} ... {[output_file_options] output_url}</span></code></pre></figure>

<p>Let’s detail the arguments used here :</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">-video_size 1920x1080</code> indicates the size of the region to grab.</li>
  <li><code class="language-plaintext highlighter-rouge">-framerate 5</code> only grabs 5 frames per second. This is below our requirement but this allows somewhat smooth testing of the setup before optimization.</li>
  <li><a href="https://ffmpeg.org/ffmpeg-devices.html#x11grab"><code class="language-plaintext highlighter-rouge">-f x11grab</code></a> : used as an input file option, <code class="language-plaintext highlighter-rouge">-f</code> specifies the input devie. <code class="language-plaintext highlighter-rouge">x11grab</code> is used for screen grabbing.</li>
  <li><code class="language-plaintext highlighter-rouge">-i :0.0+0x0</code> : <code class="language-plaintext highlighter-rouge">-i</code> is usually used for specifying input file. When used with the X11 video input device, specifies where to grab from in the syntax : <code class="language-plaintext highlighter-rouge">[hostname]:display_number.screen_number[+x_offset,y_offset]</code></li>
  <li><a href="https://ffmpeg.org/ffmpeg-formats.html#mpegts"><code class="language-plaintext highlighter-rouge">-f mpegts</code></a> : used as an output file option, <code class="language-plaintext highlighter-rouge">-f</code> specifies the output container (also called file format or muxer). <code class="language-plaintext highlighter-rouge">mpegts</code> designates MPEG-2 transport stream.</li>
  <li><code class="language-plaintext highlighter-rouge">tcp://10.0.0.0:1234</code> is the URL to send the stream to (the mpv listener running on the Pi)</li>
</ul>

<p>This did not meet any of my performance and quality requirements, but provided me with a starting point I could optimize from.</p>

<h3 id="optimizing-the-receiving-end-of-the-stream">Optimizing the receiving end of the stream</h3>

<p>I then tried two optimization strategies on the receiving side, which involved a lot of googling and a bunch of not-so-well documented <code class="language-plaintext highlighter-rouge">mpv</code> options :</p>

<ul>
  <li>Speeding up decoding using hardware acceleration</li>
  <li>Jumping to the latest available frame when decoding fell behind</li>
</ul>

<p>I came up with the following <code class="language-plaintext highlighter-rouge">mpv</code> command (which I will not detail) before trying another player :</p>

<figure class="highlight"><pre><code class="language-console" data-lang="console"><span class="gp">pi@raspberrypi:~ $</span><span class="w"> </span>mpv <span class="nt">-vo</span><span class="o">=</span>gpu <span class="nt">--gpu-context</span><span class="o">=</span>drm <span class="nt">--input-cursor</span><span class="o">=</span>no <span class="nt">--input-vo-keyboard</span><span class="o">=</span>no <span class="nt">--input-default-bindings</span><span class="o">=</span>no <span class="nt">--hwdec</span><span class="o">=</span>drm <span class="nt">--untimed</span> <span class="nt">--no-cache</span> <span class="nt">--profile</span><span class="o">=</span>low-latency <span class="nt">--opengl-glfinish</span><span class="o">=</span><span class="nb">yes</span> <span class="nt">--opengl-swapinterval</span><span class="o">=</span>0 <span class="nt">--gpu-hwdec-interop</span><span class="o">=</span>drmprime-drm <span class="nt">--drm-draw-plane</span><span class="o">=</span>overlay <span class="nt">--drm-drmprime-video-plane</span><span class="o">=</span>primary <span class="nt">--framedrop</span><span class="o">=</span>no <span class="nt">--speed</span><span class="o">=</span>1.01 <span class="nt">--video-latency-hacks</span><span class="o">=</span><span class="nb">yes</span> <span class="nt">--opengl-glfinish</span><span class="o">=</span><span class="nb">yes</span> <span class="nt">--opengl-swapinterval</span><span class="o">=</span>0 tcp://10.0.0.0:1234<span class="se">\?</span>listen</code></pre></figure>

<p>While this achieved the best latency I could reach using <code class="language-plaintext highlighter-rouge">mpv</code> and the basic <code class="language-plaintext highlighter-rouge">ffmpeg</code> command above, I felt this was too complicated. Some other resources I found online were using <a href="https://ffmpeg.org/ffplay.html"><code class="language-plaintext highlighter-rouge">ffplay</code></a> on the receiving end so I gave it a try. This proved to be a much simpler path, and I achieved comparable results using the following command :</p>

<figure class="highlight"><pre><code class="language-console" data-lang="console"><span class="gp">pi@raspberrypi:~ $</span><span class="w"> </span>ffplay <span class="nt">-autoexit</span> <span class="nt">-flags</span> low_delay <span class="nt">-framedrop</span> <span class="nt">-strict</span> experimental <span class="nt">-vf</span> <span class="nv">setpts</span><span class="o">=</span>0 <span class="nt">-tcp_nodelay</span> 1 <span class="s2">"tcp://10.0.0.0:1234</span><span class="se">\?</span><span class="s2">listen"</span></code></pre></figure>

<p>Most of these optimizations came from <a href="https://stackoverflow.com/questions/16658873/how-to-minimize-the-delay-in-a-live-streaming-with-ffmpeg">this stackoverflow post about minimizing delay in a live stream</a>. Let’s detail the meaning of the options I used :</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">-autoexit</code> makes <code class="language-plaintext highlighter-rouge">ffplay</code> exit when the stream ends</li>
  <li><a href="https://ffmpeg.org/ffplay-all.html#Codec-Options"><code class="language-plaintext highlighter-rouge">-flags low_delay</code></a> seemed like an obvious choice, even if the documentation is not clear about what it does</li>
  <li><a href="https://ffmpeg.org/ffplay-all.html#Advanced-options"><code class="language-plaintext highlighter-rouge">-framedrop</code></a> “Drop video frames if video is out of sync”</li>
  <li><a href="https://ffmpeg.org/ffplay-all.html#Codec-Options"><code class="language-plaintext highlighter-rouge">-strict experimental</code></a> enables “unfinished/work in progress/not well tested” stuff. This proved to be useful. Note : the documentation mentions this option not being suitable for decoding untrusted input. You should probably remove it if you plan on plugging untrusted computers on your Raspberry Pi’s LAN port.</li>
  <li><a href="https://ffmpeg.org/ffplay-all.html#setpts_002c-asetpts"><code class="language-plaintext highlighter-rouge">-vf setpts=0</code></a> : <code class="language-plaintext highlighter-rouge">-vf</code> is used to specify video filters. The <code class="language-plaintext highlighter-rouge">setpts</code> filter changes the <em>Presentation TimeStamp</em> of video frames. <code class="language-plaintext highlighter-rouge">setpts=0</code> is used to make all frames display as soon as possible</li>
  <li><code class="language-plaintext highlighter-rouge">-tcp_nodelay 1</code> enables the <a href="https://www.extrahop.com/company/blog/2016/tcp-nodelay-nagle-quickack-best-practices/">TCP nodelay flag</a>. I’m not sure this one really had any impact, but it made sense to include it and did not hurt performances.</li>
</ul>

<p>The stream sent by the basic <code class="language-plaintext highlighter-rouge">ffmpeg</code> command gets displayed on the Pi monitor with a delay of approximately 1 second using <code class="language-plaintext highlighter-rouge">ffplay</code>. This is too high, and the quality is too low for small text, but we are very close to the final command I’m still running on the Pi.</p>

<p>Let’s make sure the OS prioritizes the <code class="language-plaintext highlighter-rouge">ffplay</code> process using the <code class="language-plaintext highlighter-rouge">nice</code> and <code class="language-plaintext highlighter-rouge">ionice</code> commands :</p>

<figure class="highlight"><pre><code class="language-console" data-lang="console"><span class="gp">pi@raspberrypi:~ $</span><span class="w"> </span><span class="nb">sudo nice</span> <span class="nt">-n</span> <span class="nt">-20</span> ionice <span class="nt">-c</span> 1 <span class="nt">-n</span> 0 ffplay <span class="nt">-autoexit</span> <span class="nt">-flags</span> low_delay <span class="nt">-framedrop</span> <span class="nt">-strict</span> experimental <span class="nt">-vf</span> <span class="nv">setpts</span><span class="o">=</span>0 <span class="nt">-tcp_nodelay</span> 1 <span class="s2">"tcp://10.0.0.0:1234</span><span class="se">\?</span><span class="s2">listen"</span></code></pre></figure>

<h3 id="supervising-ffplay">Supervising <code class="language-plaintext highlighter-rouge">ffplay</code></h3>

<p>Since the player automatically detects, decodes and demuxes the input codec and muxer, I could experiment with the sending side without changing the command run on the Pi. However, I still had to switch between terminals in order to manually restart <code class="language-plaintext highlighter-rouge">ffplay</code> between each try. This pushed me to take care of a non-essential feature before going on.</p>

<p>I used <a href="http://supervisord.org/"><code class="language-plaintext highlighter-rouge">supervisor</code></a> to manage the media player process. The choice was motivated by its ease of use over creating systemd services.</p>

<figure class="highlight"><pre><code class="language-console" data-lang="console"><span class="gp">pi@raspberrypi:~ $</span><span class="w"> </span><span class="nb">sudo </span>apt-get <span class="nb">install </span>supervisor
<span class="gp">pi@raspberrypi:~ $</span><span class="w"> </span>sudoedit /etc/supervisor/conf.d/pimonitor.conf</code></pre></figure>

<p>This will install <code class="language-plaintext highlighter-rouge">supervisor</code> and open a configuration file for editing. I used the following content :</p>

<figure class="highlight"><pre><code class="language-conf" data-lang="conf">[<span class="n">program</span>:<span class="n">ffplay</span>]
<span class="n">command</span>=<span class="n">nice</span> -<span class="n">n</span> -<span class="m">20</span> <span class="n">ionice</span> -<span class="n">c</span> <span class="m">1</span> -<span class="n">n</span> <span class="m">0</span> <span class="n">ffplay</span> -<span class="n">autoexit</span> -<span class="n">flags</span> <span class="n">low_delay</span> -<span class="n">framedrop</span> -<span class="n">strict</span> <span class="n">experimental</span> -<span class="n">vf</span> <span class="n">setpts</span>=<span class="m">0</span> -<span class="n">tcp_nodelay</span> <span class="m">1</span> <span class="s2">"tcp://10.0.0.0:1234\?listen"</span>
<span class="n">autorestart</span>=<span class="n">true</span>
<span class="n">stdout_logfile</span>=/<span class="n">dev</span>/<span class="n">null</span>
<span class="n">stderr_logfile</span>=/<span class="n">dev</span>/<span class="n">null</span></code></pre></figure>

<p>The “autorestart” option makes a new instance of ffplay listen and wait for a new stream when the previous one exits. I used <code class="language-plaintext highlighter-rouge">/dev/null</code> for logfiles to prevent <code class="language-plaintext highlighter-rouge">ffplay</code>’s verbose output from filling my small SD card with log files.</p>

<p>After starting the <code class="language-plaintext highlighter-rouge">supervisor</code> daemon with <code class="language-plaintext highlighter-rouge">sudo systemctl enable supervisor</code> and <code class="language-plaintext highlighter-rouge">sudo systemctl start supervisor</code>, I could try <code class="language-plaintext highlighter-rouge">ffmpeg</code> option combinations much quicker.</p>

<h3 id="fine-tuning-the-encoder-process">Fine-tuning the encoder process</h3>

<p>The first thing I did was increase the framerate to 30 FPS, and I was really surprised to find ouy this helped a lot with latency. The encoder would still occasionally fall behind, which caused latency spikes, but the with that simple change it suddenly started to feel like I was on the right track.</p>

<p>I then tried switching from the default <code class="language-plaintext highlighter-rouge">mpeg2video</code> to the more modern <code class="language-plaintext highlighter-rouge">mpeg4</code> which did not lead to any improvement in itself, but provided more options. Switching the muxer from <code class="language-plaintext highlighter-rouge">mpegts</code> to <code class="language-plaintext highlighter-rouge">nut</code> led to more noticeable improvements regarding delay. While quality was still too low, it started to feel responsive enough to meet the latency requirement.</p>

<p>I then managed to increase the quality to my standards by using encoder options to target a higher bit-rate (<code class="language-plaintext highlighter-rouge">-b:v 40M -maxrate 50M -bufsize 200M</code>). However, the Raspberry Pi became overloaded and started to drop a couple of frames a few times per seconds. This led to an unpleasant experience, with the mouse movements and scrolling not feeling smooth. What surprised me the most was seeing frames being dropped even when displaying a still screen.</p>

<p>At this point, I was back to square one, trying to find the balance between quality and framerate. One key difference, however, was that this time I was working with tools that provided with more than enough options. After trying a few things that did not work, I noticed a few things :</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">ffmpeg</code> was sending a stream with a bitrate of several Mbit/s for a still screen.</li>
  <li>Framedrops from <code class="language-plaintext highlighter-rouge">ffplay</code> seemed to happen at a very stable rate.</li>
  <li>The Raspberry Pi did not seem to be limited by its CPU.</li>
</ul>

<p>This hinted to me that the problem came from the network, so I launched a network capture using tcpdump :</p>

<figure class="highlight"><pre><code class="language-console" data-lang="console"><span class="gp">pierre@laptop:~ $</span><span class="w"> </span><span class="nb">sudo </span>tcpdump <span class="nt">-i</span> eth0 <span class="nt">-c</span> 2000 <span class="nt">-w</span> diag_remote_screen.pcapng <span class="s2">"port 1234"</span>
<span class="gp">pierre@laptop:~ $</span><span class="w"> </span>tcpdump <span class="nt">-r</span> diag_remote_screen.pcapng | <span class="nb">awk</span> <span class="s1">'{ print $1 " " $8 " " $9 " " $NF }'</span> | less</code></pre></figure>

<p>This captures 2000 packets of the stream between <code class="language-plaintext highlighter-rouge">ffmpeg</code> running on the laptop and <code class="language-plaintext highlighter-rouge">ffplay</code> running on the Pi. The second command is used to examine the captured packets, but you can also open the <code class="language-plaintext highlighter-rouge">.pcapng</code> file with Wireshark or other similar tools.</p>

<p>The command above shows :</p>

<ul>
  <li>The time at which the packet was captured</li>
  <li>The TCP sequence number for packets from the laptop to the Pi and their acknowledgements</li>
  <li>The size of packets</li>
</ul>

<p>Here is a sample of its output :</p>

<figure class="highlight"><pre><code class="language-console" data-lang="console"><span class="go">14:13:36.879965 seq 79239:81556, 2317
14:13:36.881709 ack 81556, 0
14:13:36.916838 seq 81556:83849, 2293
14:13:36.918185 ack 83849, 0
14:13:36.943326 seq 83849:85014, 1165
14:13:36.944438 ack 85014, 0
14:13:36.981337 seq 85014:87613, 2599
14:13:36.982724 ack 87613, 0
14:13:37.014469 seq 87613:88769, 1156
14:13:37.015752 ack 88769, 0
14:13:37.054639 seq 88769:90701, 1932
14:13:37.055851 ack 90701, 0
14:13:37.077741 seq 90701:91858, 1157
14:13:37.079045 ack 91858, 0
14:13:37.121258 seq 91858:107786, 15928
14:13:37.121301 seq 107786:123714, 15928
14:13:37.121324 seq 123714:124626, 912
14:13:37.121360 seq 124626:140554, 15928
14:13:37.121374 seq 140554:156482, 15928
14:13:37.121386 seq 156482:172410, 15928
14:13:37.121391 seq 172410:188338, 15928
14:13:37.121403 seq 188338:204266, 15928
14:13:37.121410 seq 204266:220194, 15928
14:13:37.121421 seq 220194:236122, 15928
14:13:37.121426 seq 236122:252050, 15928
14:13:37.121438 seq 252050:267978, 15928
14:13:37.122535 seq 267978:283906, 15928
14:13:37.122567 ack 94754, 0
14:13:37.122567 ack 97650, 0
14:13:37.122567 ack 100546, 0
14:13:37.122585 seq 283906:299834, 15928
14:13:37.123237 ack 103442, 0
14:13:37.123237 ack 106338, 0
14:13:37.123238 ack 109234, 0
14:13:37.123255 seq 299834:315762, 15928
14:13:37.123891 seq 315762:331690, 15928
14:13:37.123916 seq 331690:347618, 15928
14:13:37.123926 ack 112130, 0
    [LOTS OF SUCCESSIVE ACKs]
14:13:37.135636 ack 254946, 0
14:13:37.136070 seq 347618:363546, 15928
14:13:37.136273 ack 257842, 0
14:13:37.136273 ack 260738, 0
14:13:37.136273 ack 263634, 0
14:13:37.136989 ack 266530, 0
14:13:37.136989 ack 269426, 0
14:13:37.136989 ack 272322, 0
    [REPEAT 25x THE ABOVE PATTERN OF A 15928 BYTES TCP PACKET FOLLOWED BY A FEW ACKs]
14:13:37.168585 seq 745818:761746, 15928
14:13:37.169275 ack 645906, 0
14:13:37.169275 ack 648802, 0
14:13:37.169275 ack 651698, 0
14:13:37.169857 seq 761746:769413, 7667
14:13:37.170274 ack 654594, 0
    [LOTS OF SUCCESSIVE ACKs]
14:13:37.179345 ack 769413, 0
14:13:37.184011 seq 769413:770863, 1450
14:13:37.185333 ack 770863, 0
14:13:37.214388 seq 770863:772194, 1331
14:13:37.215822 ack 772194, 0
14:13:37.241472 seq 772194:774010, 1816
14:13:37.243176 ack 774010, 0</span></code></pre></figure>

<p>At first, we see the laptop sends a packet that weights a couple kB approximately every 0.035s, which matches our framerate of 30fps. The Pi sends the acknowledgements for these packets before the next one comes in. At <code class="language-plaintext highlighter-rouge">14:13:37.121258</code>, ffmpeg starts sending a lot of 16kb packets to the Pi and the acknowledgement numbers start falling behind. When the Pi gets too far behind, ffmpeg waits for ACKs to catch-up a little before sending more data (TCP sequence numbers <code class="language-plaintext highlighter-rouge">283906-769413</code>). This burst of data from the laptop stops at <code class="language-plaintext highlighter-rouge">14:13:37.169857</code> and the Pi TCP stack finally catches up at <code class="language-plaintext highlighter-rouge">14:13:37.179345</code>. This is <code class="language-plaintext highlighter-rouge">0.58s</code> (almost 2 frames) after the laptop began sending this data. This whole thing happened precisely every 12 frames and explained the details I noticed earlier about the framedrops.</p>

<p>The mpeg codec compresses videos by only saving a few frames in full. These are called keyframes. All other frames are derived from the frame that comes before associated with a description of the differences between consecutive frames. The data bursts happened everytime ffmpeg sent a keyframe, which by default was every 12 frame (~ 3 times/sec).</p>

<p>Increasing the “group of picture” <a href="https://ffmpeg.org/ffmpeg-codecs.html#Codec-Options">codec option</a> from 12 to 100 (~ once every 3 seconds) had the expected effect : framedrops were only happening once every 3 seconds, which I could live with.</p>

<p>At this point I had the following command :</p>

<figure class="highlight"><pre><code class="language-console" data-lang="console"><span class="gp">pierre@laptop:~ $</span><span class="w"> </span>ffmpeg <span class="nt">-video_size</span> 1920x1080 <span class="nt">-framerate</span> 30 <span class="nt">-f</span> x11grab <span class="nt">-i</span> :0.0+0x0 <span class="nt">-b</span>:v 40M <span class="nt">-maxrate</span> 50M <span class="nt">-bufsize</span> 200M <span class="nt">-vcodec</span> mpeg4 <span class="nt">-g</span> 100 <span class="nt">-f</span> nut <span class="s2">"tcp://10.0.0.0:1234"</span></code></pre></figure>

<p>Even though I was satisfied with what I managed to get, I kept tinkering with options. At one point, it became difficult to tell what actually improved the experience and what could be attributed to some kind of placebo effect. Anyway, here is the final command I came up with :</p>

<figure class="highlight"><pre><code class="language-console" data-lang="console"><span class="gp">pierre@laptop:~ $</span><span class="w"> </span>ffmpeg <span class="nt">-video_size</span> 1920x1080 <span class="nt">-r</span> 30 <span class="nt">-framerate</span> 30 <span class="nt">-f</span> x11grab <span class="nt">-i</span> :0.0+0x0 <span class="se">\</span>
<span class="go">    -b:v 40M -maxrate 50M -bufsize 200M \
    -field_order tt -fflags nobuffer -threads 1 \
    -vcodec mpeg4 -g 100 -r 30 -bf 0 -mbd bits -flags +aic+mv4+low_delay \
    -thread_type slice -slices 1 -level 32 -strict experimental -f_strict experimental \
    -syncpoints none -f nut "tcp://10.0.0.0:1234"</span></code></pre></figure>

<h3 id="extending-the-laptop-display">Extending the laptop display</h3>

<p>For this part, I intended to configure the X server on my laptop to be able to output to a virtual monitor, which I could then screen-grab and stream to the Raspberry Pi.
I closely followed what <a href="https://github.com/dianariyanto/virtual-display-linux"><code class="language-plaintext highlighter-rouge">virtual-display-linux</code></a> does. I copied the <a href="https://github.com/dianariyanto/virtual-display-linux/blob/master/20-intel.conf">provided configuration file for intel GPU</a>. After rebooting, I could indeed see two monitors called <code class="language-plaintext highlighter-rouge">VIRTUAL1</code> and <code class="language-plaintext highlighter-rouge">VIRTUAL2</code> in my <code class="language-plaintext highlighter-rouge">xrandr</code> output.</p>

<p>Using the accepted answer from <a href="https://unix.stackexchange.com/questions/227876/how-to-set-custom-resolution-using-xrandr-when-the-resolution-is-not-available-i">this stackoverflow thread</a> I created the mode for my external monitor resolution and associated it with the first virtual display :</p>

<figure class="highlight"><pre><code class="language-console" data-lang="console"><span class="gp">pierre@laptop:~ $</span><span class="w"> </span>gtf 1920 1200 30 <span class="c"># gtf {W} {H} {FPS}</span>
<span class="gp">#</span><span class="w"> </span>Use the Modeline from the output of the above <span class="nb">command </span><span class="k">in </span>the <span class="nb">command </span>below
<span class="gp">pierre@laptop:~ $</span><span class="w"> </span>xrandr <span class="nt">--newmode</span> <span class="s2">"1920x1200_30.00"</span>  89.67  1920 1992 2184 2448  1200 1201 1204 1221  <span class="nt">-HSync</span> +Vsync
<span class="gp">pierre@laptop:~ $</span><span class="w"> </span>xrandr <span class="nt">--addmode</span> VIRTUAL1 <span class="s2">"1920x1200_30.00"</span></code></pre></figure>

<p>Note that I used a resolution of 1920x1200 because this is the resolution of the monitor I’m using. If you are following along, you will need to change this to fit your actual screen resolution.</p>

<p>After enabling the virtual monitor using <code class="language-plaintext highlighter-rouge">arandr</code> (a graphical frontend for <code class="language-plaintext highlighter-rouge">xrandr</code>), I modified the <code class="language-plaintext highlighter-rouge">-video_size</code> and <code class="language-plaintext highlighter-rouge">-i</code> options in my ffmpeg command to grab the virtual display. This worked as intended and it effectively extended my laptop’s display to the Pi-drived monitor.</p>

<h3 id="wrapping-xrandr">Wrapping <code class="language-plaintext highlighter-rouge">xrandr</code></h3>

<p>At this point, my solution was meeting all my primary requirements. I was able to set everything up so it really felt like using a regular monitor. However, I still had to run a bunch of commands by hand on the laptop. How nice would it be to enable the virtual display just like a regular one, and have the <code class="language-plaintext highlighter-rouge">ffmpeg</code> command run automatically with the right options ?</p>

<p>The solution I came up with feels a bit hacky : I wrote a wrapper script for <code class="language-plaintext highlighter-rouge">xrandr</code>.</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="c">#!/bin/bash</span>

<span class="c"># Enable job control</span>
<span class="nb">set</span> <span class="nt">-m</span>

<span class="c"># Extract arguments between `--output VIRTUAL1` and the next occurence of `--output`</span>
<span class="nv">V_ARGS</span><span class="o">=</span><span class="si">$(</span><span class="nb">echo</span> <span class="s2">"</span><span class="nv">$@</span><span class="s2">"</span> | <span class="nb">grep</span> <span class="s2">"VIRTUAL1"</span> | <span class="nb">sed</span> <span class="nt">-e</span> <span class="s1">'s/.*--output VIRTUAL1 //'</span> <span class="nt">-e</span> <span class="s1">'s/ \?--output.*//'</span><span class="si">)</span>

<span class="c"># Run the real xrandr</span>
<span class="c"># (using full path YOU MAY NEED TO UPDATE THIS DEPENDING ON YOUR DISTRO)</span>
/usr/bin/xrandr <span class="s2">"</span><span class="nv">$@</span><span class="s2">"</span>

<span class="c"># If xrandr exited with an error, exit with the same exit code</span>
<span class="nv">EXITCODE</span><span class="o">=</span><span class="nv">$?</span>
<span class="k">if</span> <span class="o">[</span> <span class="si">$(</span><span class="nb">echo</span> <span class="nv">$V_ARGS</span> | <span class="nb">wc</span> <span class="nt">-w</span><span class="si">)</span> <span class="nt">-eq</span> 0 <span class="o">]</span><span class="p">;</span> <span class="k">then
    </span><span class="nb">exit</span> <span class="nv">$EXITCODE</span>
<span class="k">fi</span>

<span class="c"># Kill the previous ffmpeg process if it exists</span>
<span class="nb">kill</span> <span class="si">$(</span><span class="nb">cat</span> /tmp/remote_screen_ffmpeg.pid<span class="si">)</span>
<span class="nv">KILLEDFFMPEG</span><span class="o">=</span><span class="nv">$?</span>
<span class="nb">rm</span> /tmp/remote_screen_ffmpeg.pid

<span class="c"># If the arguments for the display contain `--off`</span>
<span class="k">if</span> <span class="o">[</span> <span class="si">$(</span><span class="nb">echo</span> <span class="nv">$V_ARGS</span> | <span class="nb">grep</span> <span class="nt">-e</span> <span class="s2">"--off"</span> | <span class="nb">wc</span> <span class="nt">-l</span><span class="si">)</span> <span class="nt">-ge</span> 1 <span class="o">]</span><span class="p">;</span> <span class="k">then
    </span><span class="nb">echo</span> <span class="s2">"Screen off"</span> <span class="o">&gt;&gt;</span> ~/testxrandr <span class="c"># For debugging</span>
<span class="k">else</span>
    <span class="c"># Extract the arguments for the display we're interested in</span>
    <span class="nv">MODE</span><span class="o">=</span><span class="si">$(</span><span class="nb">echo</span> <span class="nv">$V_ARGS</span> | <span class="nb">sed</span> <span class="nt">-e</span> <span class="s1">'s/.*--mode \([^ ]*\).*/\1/'</span><span class="si">)</span>
    <span class="nv">POS</span><span class="o">=</span><span class="si">$(</span><span class="nb">echo</span> <span class="nv">$V_ARGS</span> | <span class="nb">sed</span> <span class="nt">-e</span> <span class="s1">'s/.*--pos \([^ ]*\).*/\1/'</span><span class="si">)</span>
    <span class="nv">ROTATE</span><span class="o">=</span><span class="si">$(</span><span class="nb">echo</span> <span class="nv">$V_ARGS</span> | <span class="nb">sed</span> <span class="nt">-e</span> <span class="s1">'s/.*--rotate \([^ ]*\).*/\1/'</span><span class="si">)</span>

    <span class="c"># If the display is rotated, invert width and height in $MODE</span>
    <span class="k">if</span> <span class="o">[[</span> <span class="nv">$ROTATE</span> <span class="o">==</span> <span class="s2">"left"</span> <span class="o">]]</span> <span class="o">||</span> <span class="o">[[</span> <span class="nv">$ROTATE</span> <span class="o">==</span> <span class="s2">"right"</span> <span class="o">]]</span><span class="p">;</span> <span class="k">then
        </span><span class="nv">MODE</span><span class="o">=</span><span class="si">$(</span><span class="nb">echo</span> <span class="nv">$MODE</span> | <span class="nb">sed</span> <span class="nt">-e</span> <span class="s1">'s/\([0-9]*\)x\([0-9]*\)/\2x\1/'</span><span class="si">)</span>
    <span class="k">fi</span>

    <span class="c"># $VFARG will be used later in an ffmpeg option</span>
    <span class="k">case</span> <span class="nv">$ROTATE</span> <span class="k">in
        </span>normal<span class="p">)</span>
            <span class="nv">VFARG</span><span class="o">=</span><span class="s2">"null"</span>
            <span class="p">;;</span>
        left<span class="p">)</span>
            <span class="nv">VFARG</span><span class="o">=</span><span class="s2">"transpose=2"</span>
            <span class="p">;;</span>
        right<span class="p">)</span>
            <span class="nv">VFARG</span><span class="o">=</span><span class="s2">"transpose=1"</span>
            <span class="p">;;</span>
        inverted<span class="p">)</span>
            <span class="nv">VFARG</span><span class="o">=</span><span class="s2">"transpose=2,transpose=2"</span>
            <span class="p">;;</span>
        <span class="k">*</span><span class="p">)</span>
            <span class="nv">VFARG</span><span class="o">=</span><span class="s2">"null"</span>
            <span class="p">;;</span>
    <span class="k">esac</span>

    <span class="c"># If there was a previously running ffmpeg process which we killed,</span>
    <span class="c"># wait 5 seconds for the supervisor daemon on the Pi to restart ffplay</span>
    <span class="k">if</span> <span class="o">[</span> <span class="nv">$KILLEDFFMPEG</span> <span class="o">]</span><span class="p">;</span> <span class="k">then
        </span><span class="nb">sleep </span>5
    <span class="k">fi</span>

    <span class="c"># ffmpeg command, the magic happens here</span>
    taskset <span class="nt">-c</span> 0 ffmpeg <span class="nt">-nostdin</span> <span class="se">\</span>
        <span class="nt">-video_size</span> <span class="nv">$MODE</span> <span class="nt">-r</span> 30 <span class="nt">-framerate</span> 30 <span class="nt">-f</span> x11grab <span class="nt">-i</span> :0.0+<span class="nv">$POS</span> <span class="se">\</span>
        <span class="nt">-b</span>:v 40M <span class="nt">-maxrate</span> 50M <span class="nt">-minrate</span> 1K <span class="nt">-bufsize</span> 200M <span class="se">\</span>
        <span class="nt">-field_order</span> tt <span class="nt">-fflags</span> nobuffer <span class="nt">-threads</span> 1 <span class="se">\</span>
        <span class="nt">-vcodec</span> mpeg4 <span class="nt">-g</span> 100 <span class="nt">-r</span> 30 <span class="nt">-bf</span> 0 <span class="se">\</span>
        <span class="nt">-mbd</span> bits <span class="nt">-me_method</span> full <span class="nt">-flags</span> +aic+mv4+low_delay <span class="nt">-me_method</span> full <span class="se">\</span>
        <span class="nt">-thread_type</span> slice <span class="nt">-slices</span> 1 <span class="nt">-level</span> 32 <span class="se">\</span>
        <span class="nt">-strict</span> experimental <span class="nt">-f_strict</span> experimental <span class="nt">-syncpoints</span> none <span class="se">\</span>
        <span class="nt">-vf</span> <span class="s2">"</span><span class="nv">$VFARG</span><span class="s2">"</span> <span class="nt">-f</span> nut <span class="nt">-tcp_nodelay</span> 1 <span class="se">\</span>
        <span class="s2">"tcp://10.0.0.0:1234?tcp_nodelay=1"</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1 &amp;

    <span class="c"># Save the ffmpeg pid to a file which we'll read on next invocation</span>
    <span class="nv">FFMPEGPID</span><span class="o">=</span><span class="nv">$!</span>
    <span class="nb">disown</span> <span class="nv">$FFMPEGPID</span>
    <span class="nb">echo</span> <span class="nv">$FFMPEGPID</span> <span class="o">&gt;</span> /tmp/remote_screen_ffmpeg.pid
<span class="k">fi</span>

<span class="c"># Return the same exit code as xrandr did</span>
<span class="nb">exit</span> <span class="nv">$EXITCODE</span></code></pre></figure>

<p>You can recognize the <code class="language-plaintext highlighter-rouge">ffmpeg</code> command from earlier. There are however a few different things :</p>

<ul>
  <li>The <code class="language-plaintext highlighter-rouge">-video_size</code> and <code class="language-plaintext highlighter-rouge">-i</code> options are determined from the <code class="language-plaintext highlighter-rouge">xrandr</code> invocation</li>
  <li>Depending on the screen orientation, we use a <a href="https://ffmpeg.org/ffmpeg-filters.html#transpose-1">video filter</a> to rotate the stream</li>
  <li>ffmpeg is invoked through <a href="https://manpages.ubuntu.com/manpages/trusty/fr/man1/taskset.1.html"><code class="language-plaintext highlighter-rouge">taskset</code></a></li>
</ul>

<p>I saved this script as <code class="language-plaintext highlighter-rouge">~/.local/bin/xrandr</code>. For this to work, you need to have your <code class="language-plaintext highlighter-rouge">~/.local/bin</code> directory in your path, with a higher priority than system-wide directories. This is achieved by adding the following line in your <code class="language-plaintext highlighter-rouge">~/.bashrc</code> (or whatever rc file your shell uses) :</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nb">export </span><span class="nv">PATH</span><span class="o">=</span><span class="s2">"</span><span class="nv">$HOME</span><span class="s2">/.local/bin:</span><span class="nv">$PATH</span><span class="s2">"</span></code></pre></figure>

<p>This wrapper script is run everytime I run a <code class="language-plaintext highlighter-rouge">xrandr</code> command, including from GUI frontends such as <code class="language-plaintext highlighter-rouge">arandr</code>. It manages the <code class="language-plaintext highlighter-rouge">ffmpeg</code> process and starts the stream whenever the <code class="language-plaintext highlighter-rouge">VIRTUAL1</code> display is enabled. It even manages screen orientation, which was essential to me since I actually use this monitor in portrait orientation.</p>

<h3 id="managing-power">Managing power</h3>

<p>After writing the wrapper script, I was really happy with the result. I even got the pleasant surprise of not having to handle resuming the stream after the laptop wakes up from sleep. Since <code class="language-plaintext highlighter-rouge">ffmpeg</code> was not exiting on sleep, <code class="language-plaintext highlighter-rouge">ffplay</code> silently waited for the laptop to start sending data again. There was one thing bothering me though : I still had to manually power the monitor on and off when leaving my desk.</p>

<p>I googled for how to turn the HDMI port of the Raspberry Pi on and off, and quickly found out about the <a href="https://elinux.org/RPI_vcgencmd_usage"><code class="language-plaintext highlighter-rouge">vcgencmd</code></a> command and its <code class="language-plaintext highlighter-rouge">display_power</code> subcommand. Unfortunately, every command I tried seemed to have no effect on the Raspberry Pi 3. It took me a few days to <a href="https://forum.magicmirror.builders/topic/16865/mmm-remotecontrol-or-vcgencmd-issue">find a fix</a> : by editing the <code class="language-plaintext highlighter-rouge">/boot/config.txt</code> to replace <code class="language-plaintext highlighter-rouge">dtoverlay=vc4-kms-v3d</code> with <code class="language-plaintext highlighter-rouge">dtoverlay=vc4-fkms-v3d</code> and rebooting the Pi, it worked. It seems like the “kms” driver has a bug on the Raspberry Pi 3. Fortunately, switching VideoCore drivers did not impact the stream decoding performance. With that issue fixed, I was able to turn the screen on and off from an SSH session.</p>

<p>In order to run the right commands, I once again went the hacky way and came up with a short script :</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="c">#!/bin/bash</span>

<span class="k">while </span><span class="nb">true</span><span class="p">;</span> <span class="k">do
	if</span> <span class="o">[</span> <span class="si">$(</span><span class="nb">sudo timeout </span>2 tcpdump <span class="nt">-i</span> eth0 <span class="s2">"port 1234"</span> | <span class="nb">wc</span> <span class="nt">-l</span><span class="si">)</span> <span class="nt">-gt</span> 1 <span class="o">]</span><span class="p">;</span> <span class="k">then
		</span>vcgencmd display_power 1 2
	<span class="k">else
		</span>vcgencmd display_power 0 2
	<span class="k">fi
done</span></code></pre></figure>

<p>This is a dirty infinite loop which does the following :</p>

<ul>
  <li>Run <code class="language-plaintext highlighter-rouge">tcpdump</code> for two seconds and count the number of packets received on port 1234 during this time</li>
  <li>If there was at least one packet received during the last 2 seconds, turn the display on</li>
  <li>If no packets were received during the last 2 seconds, turn the display off</li>
  <li>Repeat</li>
</ul>

<p>I saved the script on the Pi as <code class="language-plaintext highlighter-rouge">/home/pi/check_screen_input.sh</code> and edited the <code class="language-plaintext highlighter-rouge">supervisor</code> configuration file :</p>

<figure class="highlight"><pre><code class="language-conf" data-lang="conf">[<span class="n">program</span>:<span class="n">power_mgmt</span>]
<span class="n">command</span>=/<span class="n">home</span>/<span class="n">pi</span>/<span class="n">check_screen_input</span>.<span class="n">sh</span>
<span class="n">autorestart</span>=<span class="n">true</span></code></pre></figure>

<p>I then restarted the <code class="language-plaintext highlighter-rouge">supervisor</code> daemon, which had the effect of stopping the stream. The monitor went back to the Pi tty and after a short moment, turned off. I then disabled and re-enabled the <code class="language-plaintext highlighter-rouge">VIRTUAL1</code> display on my laptop, and the magic happened : the monitor woke up from sleep and extended the laptop’s display.</p>

<h2 id="improvements-and-last-thoughts">Improvements and last thoughts</h2>

<p>I finally reached a solution I could use in my day-to-day life, with only small quirks I don’t mind dealing with.</p>

<p>I still have to manually create the new mode and add it to the virtual display after every reboot. It would be really nice to have the Pi detect the resolution of the monitor and use it to automatically configure the virtual display on the laptop. However, since I’m of the kind who rarely reboots their computers and I already spent quite some time on this project, I moved on from it without taking care of this part.</p>

<p>I would also like to turn this whole project into a git repository with scripts and configuration files to go from a fresh Raspberry Pi OS install to the setup presented here. If there’s interest, I might even take the time to make a ready-to-flash SD image to make the process as painless as possible.</p>

<p>Overall, I am really satisfied with what I managed to come up with.</p>


        </div>
    </body>
</html>
